<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="Kaiwen Wei">
  <title>Kaiwen Wei's Homepage</title>

  <!-- CSS  -->
  <link href="./materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./style.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link rel="shortcut icon" href="./cqu_short.png">
<script type="text/javascript" src="./jquery-1.12.4.min.js.下载"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://kaiwenwei.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://kaiwenwei.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#publications">Publications</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#WorkExperience">Work Experience</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#education">Education</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#awards">Awards</a></li>
        </ul>
        </ul>
      </div>
    </nav>
  </div>
  

<!--==========================================
                   Profile
===========================================-->

<div id="home" class="parallax-container scrollspy">


  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="./wkw.jpg" width="319">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name"><font color="#000000">Kaiwen Wei (魏楷文)</h5>
        <hr>
        <h6 class="profile-link"><b>Assistant Researcher in Chongqing University</b></h6>
        <h6 class="profile-link"><b>Ph.D. at University of Chinese Academy of Sciences/Aerospace Information Research Institute, Chinese Academy of Sciences</b></h6>
        <h6 class="profile-link"><b>Email: weikaiwen@cqu.edu.cn</b></h6>
      
    </div>    
  
  </div>
  
<!--  <div class="parallax"><img src="./bg-yds3.jpg" alt="Unsplashed background img 1" style="display: block; transform: translate3d(-50%, 153px, 0px);"></div>-->

</div>
  
 

<!--==========================================
                   About
===========================================-->
<div id="biography">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title"> Biography [<a href="https://scholar.google.com/citations?hl=zh-CN&user=WfAS1yMAAAAJ"><b>Google Scholar</b></a>] </a>
</div>
    <hr>
    </div>
    
    <div class="row">
      <p>
        Kaiwen Wei is currently an Assistant Researcher at the College of Computer Science, Chongqing University (since September 2024). He obtained his Ph.D. (direct-track) from the National Key Laboratory of Target Cognition and Application Technology, Aerospace Information Research Institute (AIR), Chinese Academy of Sciences (September 2019-July 2024), under the supervision of Researcher Zhi Guo and Researcher Xian Sun. He completed his undergraduate studies at Chongqing University (September 2015-June 2019). During his doctoral studies, he interned at leading technology companies including Meituan, Alibaba DAMO Academy, and Kuaishou, accumulating rich industry experience and building strong industry-academia collaboration networks. 
        <!-- I am an Assistant Researcher at Chongqing University’s College of Computer Science (IEEE/CCF Member), leading a China Postdoctoral Science Foundation project and participating in a National Key R&D Program. Holding a Ph.D. from the Chinese Academy of Sciences’ Key Lab of Target Cognition (2019–2024) and a B.Eng. from Chongqing University (2015–2019), I interned at Meituan, Alibaba DAMO, and Kuaishou. My research focuses on NLP and Multimodal Learning, with 24 publications (14 first/corresponding-author in TPAMI, ACL, AAAI, etc.).
         Dongshuo Yin is currently a postdoc researcher in <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, working with <a href="https://www.tsinghua.edu.cn/info/1167/108283.htm">Prof. Shimin Hu</a> at <a href="https://www.cs.tsinghua.edu.cn/">the Department of Computer Science and Technology</a>. Before that, Dongshuo Yin received the PhD degree from <a href="https://eece.ucas.ac.cn/">School of Electronic, Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a> & <a href="http://www.aircas.ac.cn/">Institute of Electronics (Aerospace Information Research Institute), Chinese Academy of Sciences</a>, advised by <a href="http://people.ucas.ac.cn/~sunxian">Prof. Xian Sun</a>.         Dongshuo Yin's research interests include deep learning and computer vision, with a focus on remote sensing, parameter-efficient fine tuning, 3D weakly supervised object detection. -->
</a>
      </p>

      <p>
        His research focuses on cutting-edge AI technologies, particularly in <b>natural language processing</b> (NLP), <b>multimodal learning</b> (MM), <b>large language models</b> (LLMs), and <b>AI-driven medical applications</b> (AI+Medical), with a strong commitment to advancing intelligent systems for real-world healthcare solutions.
        <!-- I am an Assistant Researcher at Chongqing University’s College of Computer Science (IEEE/CCF Member), leading a China Postdoctoral Science Foundation project and participating in a National Key R&D Program. Holding a Ph.D. from the Chinese Academy of Sciences’ Key Lab of Target Cognition (2019–2024) and a B.Eng. from Chongqing University (2015–2019), I interned at Meituan, Alibaba DAMO, and Kuaishou. My research focuses on NLP and Multimodal Learning, with 24 publications (14 first/corresponding-author in TPAMI, ACL, AAAI, etc.).
         Dongshuo Yin is currently a postdoc researcher in <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, working with <a href="https://www.tsinghua.edu.cn/info/1167/108283.htm">Prof. Shimin Hu</a> at <a href="https://www.cs.tsinghua.edu.cn/">the Department of Computer Science and Technology</a>. Before that, Dongshuo Yin received the PhD degree from <a href="https://eece.ucas.ac.cn/">School of Electronic, Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a> & <a href="http://www.aircas.ac.cn/">Institute of Electronics (Aerospace Information Research Institute), Chinese Academy of Sciences</a>, advised by <a href="http://people.ucas.ac.cn/~sunxian">Prof. Xian Sun</a>.         Dongshuo Yin's research interests include deep learning and computer vision, with a focus on remote sensing, parameter-efficient fine tuning, 3D weakly supervised object detection. -->
</a>
      </p>

<!--      <p>-->
<!--        Dongshuo Yin received the B. E. degree from XXXXX, China, in 2019.-->
<!--      </p>-->
      <p>
        魏楷文，现为重庆大学计算机学院助理研究员（2024年9月至今），此前在中国科学院空天信息创新研究院目标认知与应用技术国家级重点实验室获得直博学位（2019年9月-2024年7月），师从郭智研究员和孙显研究员（国家杰青）。本科阶段就读于重庆大学（2015年9月-2019年6月）。博士期间曾先后在美团、阿里巴巴达摩院和快手等头部企业实习，积累了丰富的工业界经验并建立了良好的产学研合作网络。
      </p>
      <p> 
        我的研究聚焦人工智能前沿领域，主要包括：<b>自然语言处理</b>（NLP）的基础理论与应用创新、<b>多模态学习</b>（MM）的跨域融合方法、<b>大语言模型</b>（LLMs）的优化与部署，以及<b>人工智能与医学的交叉研究</b>（AI+Medical），致力于推动智能技术在医疗健康等关键领域的落地应用。

      </p>
    
      <p>
      如果对相关工作感兴趣，欢迎邮件联系我。同时，非常欢迎对科学研究感兴趣的本科生或研究生联系我进行线下（重庆大学虎溪校区）或线上的合作交流。
      </p>

  </div>
</div>



<!--==========================================
                   News
===========================================-->
<div id="news">

  <div class="row container">
    <div class="row">
      <div class="title">🔥 News</div>
      <hr>
    </div>
    <div class="row">
      <ul>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2025 May: &nbsp; 4 papers (1 main track and 3 findings) is accepted by ACL 2025.
          <!-- • 2025: &nbsp; Mona (CVPR 2025) has been reported by <a href="https://mp.weixin.qq.com/s/qL8IzpaFUWKBxUsodshH0w"><b>Extreme Mart</b></a>, <a href="https://mp.weixin.qq.com/s/OM0hZMX_KcEXvt0DorPhOw"><b>PaperWeekly</b></a>, <a href="https://mp.weixin.qq.com/s/NsNRmzn_haq_ly63W0WjAQ"><b>QbitAI (量子位)</b></a>, and <a href="https://mp.weixin.qq.com/s/15bO4RD8Iu0TcEfvHGYF0A"><b>Synces (机器之心)</b></a> ! -->
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024 Nov: &nbsp; One paper was accepted at ICASSP 2025.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024 Oct: &nbsp; One paper was accepted at COLING 2025.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024 Aug: &nbsp; One paper was accepted at TPAMI.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024 Aug: &nbsp; One paper was accepted at NLPCC 2024.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024 Jul: &nbsp; One paper was accepted at ECAI 2024.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024 May: &nbsp; One paper was accepted at COLING 2024.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024 Feb: &nbsp; Two papers were accepted at AAAI 2024.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2023 Dec: &nbsp; Two papers were accepted at EMNLP 2023.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2023 Oct: &nbsp; One paper was accepted at Electronics.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2023 Jul: &nbsp; Two papers were accepted at ACL 2023.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2022 Jun: &nbsp; One paper was accepted at CVPR 2023.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2023 Jan: &nbsp; One paper was accepted at KBS.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2022 Dec: &nbsp; One paper was accepted at TALLIP.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2022 Nov: &nbsp; One paper was accepted at TKDE.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2022 Oct: &nbsp; One paper was accepted at EMNLP 2022.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2022 Oct: &nbsp; One paper was accepted at KBS 2022.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2021 Aug: &nbsp; One paper was accepted at ACL 2021.
        </li>

      <!-- <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2024: &nbsp; Awarded with <font color="#0000dd"><b>CAS President Scholarship! (中国科学院院长奖，<1%)</b></font> 
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2024: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/document/10385180"><b>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</b></a>.
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2023: &nbsp; Our paper on Nature Communications has been read <a href="https://www.nature.com/articles/s41467-023-37136-1"><b>10,000+</b></a> times and has been reported by <a href="https://new.qq.com/rain/a/20230617A0131300.html"><b>Tencent News</b></a>, <a href="https://www.163.com/dy/article/I0F7AM0M0511D05M.html"><b>Netease News</b></a> and <a href="https://www.sohu.com/a/657874198_121123740"><b>Sohu News</b></a> !
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2023: &nbsp; One paper is accepted by <a href="https://www.nature.com/articles/s41467-023-37136-1"><b>Nature Communications</b></a> !
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2023: &nbsp; One paper is accepted by <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Yin_1_VS_100_Parameter-Efficient_Low_Rank_Adapter_for_Dense_Predictions_CVPR_2023_paper.html"><b>CVPR 2023 Main Track</b></a> !
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2023: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/10102360/"><b>IEEE Transactions on Intelligent Transportation Systems (TITS)</b></a>.
      </li>

      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2023: &nbsp; One paper is accepted by <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.html"><b>ICCV 2023 Main Track</b></a> !
      </li>

      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2022: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/9956875"><b>IEEE Transactions on Transactions on Multimedia (TMM)</b></a>.
      </li>

      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2022: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/9832637"><b>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</b></a>.
      </li>

      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        • 2022: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/9884328"><b>IEEE IGARSS 2022</b></a>.
      </li> -->

      </ul>
    </div>
  </div>
</div>



<!--==========================================
                   Publications
===========================================-->
<div class="section publications-section scrollspy" id="publications">

  <div class="row container">
    <div class="row">
      <div class="title">📝 Publications</div>
      <hr>
    </div>

        <!-- Publication 1 -->
        <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/1.pic.jpg" alt="Implicit Event Argument Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Implicit Event Argument Extraction With Argument-Argument Relational Knowledge</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Sun Xian, Zequn Zhang, Li Jin, Jingyuan Zhang, Jianwei Lv, and Zhi Guo</div>  
              <div class="paper-conf"><em><font color="#ff0000"><b>IEEE Transactions on Knowledge and Data Engineering</b></font> <b>(TKDE, SCI, CCF-A)</b></em></div>
              <div>
                  [<a href="https://ieeexplore.ieee.org/document/9963576">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning, </span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 2 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/2.pic.jpg" alt="Multimodal Cross-lingual Summarization">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Multimodal Cross-lingual Summarization for Videos: A Revisit in Knowledge Distillation Induced Triple-stage Training Method</div>
              <div class="paper-author">Nayu Liu<sup>*</sup>, <b>Kaiwen Wei<sup>*</sup></b>, Yong Yang, Jianhua Tao, Xian Sun, Fanglong Yao, Hongfeng Yu, Li Jin , Zhao Lv, and Cunhang Fan</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>IEEE Transactions on Pattern Analysis and Machine Intelligence</b></font> <b>(TPAMI, SCI, CCF-A, co-first author)</b></em></div>
              <div>
                  [<a href="https://ieeexplore.ieee.org/document/10643687">Paper</a>] [<a href="https://github.com/fchest/DKDSSD">Code</a>]
                  <div class="keywords">
                      <span class="keyword">Multi-modal Summary Generation, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 3 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/3.pic.jpg" alt="Open Information Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Guide the Many-to-One Assignment: Open Information Extraction via IoU-aware Optimal Transport</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Yang Yiran, Li Jin, Xian Sun, Zequn Zhang, Jingyuan Zhang, Xiaoyu Li, Linhao Zhang, Jintao Liu, and Zhi Guo.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>ACL 2023</b></font> <b>(ACL, Long paper, CCF-A)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2023.acl-long.272/">Paper</a>] 
                  <div class="keywords">
                      <span class="keyword">Information Extraction, </span>
                      <span class="keyword">Open-domain, </span>
                      <span class="keyword">Optimal Transport, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 4 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/4.pic.jpg" alt="Implicit Event Argument Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Trigger is Not Sufficient: Exploiting Frame-aware Knowledge for Implicit Event Argument Extraction</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Sun Xian, Zequn Zhang, Jingyuan Zhang, Zhi Guo, and Li Jin.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>ACL 2021</b></font> <b>(ACL, Long paper, CCF-A)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2021.acl-long.360/">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 5 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/5.pic.jpg" alt="Video Event Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Multi-View Interactions with Knowledge Distillation for Video Event Extraction</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Du Runyan, Li Jin, Jian Liu, Jianhua Yin, Linhao Zhang, Jintao Liu, Nayu Liu, Jingyuan Zhang, and Zhi Guo.</div>  
              <div class="paper-conf"><em><font color="#ff0000"><b>AAAI 2024</b></font> <b>(AAAI, CCF-A)</b></em></div>
              <div>
                  [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/29891">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Multi-modal, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 6 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/6.pic.jpg" alt="Event Causality Reasoning">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Multimodal Event Causality Reasoning with Scene Graph Enhanced Interaction Network</div>
              <div class="paper-author">Jintao Liu, <b>Kaiwen Wei<sup>†</sup></b>, and Chenglong Liu.</div>
              <div class="paper-conf"><em><font color="#ff0000"><b>AAAI 2024</b></font> <b>(AAAI, CCF-A, Corresponding author)</b></em></div>
              <div>
                  [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28724">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Causality Reasoning, </span>
                      <span class="keyword">Scene Graph, </span>
                      <span class="keyword">Multi-modal, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 7 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/7.pic.jpg" alt="Chain-of-Specificity">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Chain-of-Specificity: Enhancing Task-Specific Constraint Adherence in Large Language Models</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Jiang Zhong, Jingyuan Zhang, Hongzhi Zhang, Fuzheng Zhang, Di Zhang, Li Jin, and Yue Yu.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>COLING 2024</b></font> <b>(COLING, CCF-B)</b></em></div>
              <div>
                  [<a href="https://arxiv.org/abs/2402.15526">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Chain-of-Thought, </span>
                      <span class="keyword">Prompt Learning, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Large Language Model</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 8 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/8.pic.jpg" alt="Multimodal Cross-Lingual Summarization">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Assist Non-native Viewers: Multimodal Cross-Lingual Summarization for How2 Videos</div> 
              <div class="paper-author">Liu Nayu*, <b>Kaiwen Wei</b>*, Sun Xian, Hongfeng Yu, Fanglong Yao, Li Jin, Zhi Guo, and Guangluan Xu.</div>
              <div class="paper-conf"><em><font color="#ff0000"><b>EMNLP 2022</b></font> <b>(EMNLP, Long paper, CCF-B, Co-first author)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2022.emnlp-main.468/">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Summarization, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Multi-modal, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 9 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/9.pic.jpg" alt="Demonstration Learning">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Let Me Check the Examples: Enhancing Demonstration Learning via Explicit Imitation</div>
              <div class="paper-author">Sirui Wang, <b>Kaiwen Wei<sup>†</sup></b>, Hongzhi Zhang, Yuntao Li, and Wei Wu.</div>
              <div class="paper-conf"><em><font color="#ff0000"><b>ACL 2023</b></font> <b>(ACL, Short paper, CCF-A, Corresponding author)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2023.acl-short.93/">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Prompt-tuning, </span>
                      <span class="keyword">In-context Learning, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 10 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/10.pic.jpg" alt="HEFT Framework">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">HEFT: A History-Enhanced Feature Transfer framework for incremental event detection</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Zhang Zequn, Li Jin, Zhi Guo, Shuchao Li, Weihong Wang, and Jianwei Lv.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>Knowledge-Based Systems</b></font> <b>(KBS, SCI)</b></em></div>
              <div>
                  [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705122008061">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Continual Learning, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 11 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/11.pic.jpg" alt="Cross-lingual Relation Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">More than Syntaxes: Investigating Semantics to Zero-shot Cross-lingual Relation Extraction and Event Argument Role Labelling</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Jin Li, Zequn Zhang, Zhi Guo, Xiaoyu Li, and Qing Liu.</div>
              <div class="paper-conf"><em><font color="#ff0000"><b>ACM Transactions on Asian and Low-Resource Language Information Processing</b></font> <b>(TALLIP, SCI)</b></em></div>
              <div>
                  [<a href="https://dl.acm.org/doi/10.1145/3582261">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Multi-lingual, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 12 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/12.pic.jpg" alt="TAeKD Framework">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">TAeKD: Teacher Assistant Enhanced Knowledge Distillation for Closed-Source Multilingual Neural Machine Translation</div>
              <div class="paper-author">Bo Lv, Xin Liu, <b>Kaiwen Wei</b>, Ping Luo, and Yue Yu.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>COLING 2024</b></font> <b>(COLING, CCF-B)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2024.lrec-main.1350/">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Neural Machine Translation, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Large Language Model, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

<hr class="publication-hr">


</div>





<!-- ==========================================
                   Work experience
=========================================== -->
<div id="WorkExperience">

  <div class="row container">
    <div class="row">
      <div class="title">💼 Work Experience</div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <!-- <a href="https://www.tsinghua.edu.cn/" target="_blank"> -->
          <img src="./cqu_long.png" width="260" align="center" class="img-responsive edu-img">
        </a>
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <p></p>
        <p></p>
        <p></p>
        <div class="degree"></div>
        <div class="degree"><b>Assistant Researcher</b> in <a href="https://cs.cqu.edu.cn/index.htm">College of Computer Science, Chongqing University</a>, Chongiqng, China</div>
        <div class="date">Sep. 2024 - June. 2026</div>
      </div>
  </div>
  <hr class="publication-hr">
    <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./kuaishou.jpg" width="366">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Kuaishou Inc.</div>
            <div class="paper-author">LLM Group</div>
            <div class="paper-conf"><em><b>Internship</b>: 2024.2-2024.06</em></div>
<!--            <div>-->
<!--                [<a href="https://www.grss-ieee.org/technical-committees/image-analysis-and-data-fusion/?tab=data-fusion-contest">Website</a>]-->
<!--                [<a href="https://github.com/AICyberTeam/DFC2023-baseline">Baseline</a>]-->
<!--            </div>-->
          </div>
      </div>
      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./DAMO.png" width="366">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Alibaba Group</div>
            <div class="paper-author">DAMO Academy</div>
            <div class="paper-conf"><em><b>Internship</b>: 2023.7-2024.1</em></div>
          </div>
      </div>
      <hr class="publication-hr">
      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./meituan.jpg" width="366">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Meituan Inc.</div>
          <div class="paper-author">Knowlege Graph Group</div>
          <div class="paper-conf"><em><b>Internship</b>: 2022.11-2023.6</em></div>
        </div>
    </div>
<!--      <hr class="publication-hr">-->
</div>

<!--==========================================
                   Education
===========================================-->
<div id="education">
  <div class="row container">
    <div class="row">
      <div class="title">🎓 Education</div>
      <hr>
    </div>
    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <!-- <a href="https://www.tsinghua.edu.cn/" target="_blank"> -->
          <img src="./cqu_long.png" width="260" align="center" class="img-responsive edu-img">
        </a>
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <p></p>
        <p></p>
        <p></p>
        <div class="degree"></div>
        <div class="degree"><b>Undergraduate</b> in <a href="https://cs.cqu.edu.cn/index.htm">School of Microelectronics and Communication Engineering, Chongqing University</a>, Chongiqng, China</div>
        <div class="date">Sep. 2015 - June. 2019</div>
      </div>
  </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <!-- <a href="https://www.ucas.ac.cn/" target="_blank"> -->
            <img src="./University_of_Chinese_Academy_of_Sciences-Logo.png" width="380" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>Ph.D.</b> in <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a>, Beijing, China</div>
          <div class="date">Sep. 2019 - June. 2024</div>
        </div>
    </div>

<!--    <div class="row">-->
<!--        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">-->
<!--          <a href="https://www.whu.edu.cn/" target="_blank">-->
<!--            <img src="./whu.jpeg" style="width:110px;height:100px;" align="center" class="img-responsive edu-img">-->
<!--          </a>-->
<!--        </div>-->

<!--        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">-->
<!--          <p></p>-->
<!--          <p></p>-->
<!--          <p></p>-->
<!--          <div class="degree"><b>B.E.</b> degree from <a href="https://www.whu.edu.cn/">Wuhan University</a>, Wuhan, China</div>-->
<!--          <div class="date">Sep. 2015 - Jun.2019</div>-->
<!--        </div>-->
<!--    </div>-->
  </div>
</div>
      
<!--==========================================
              Reviewer Services
===========================================-->

<div id="reviewerServices">
  <div class="row container">
    <div class="row">
      <div class="title">👓 Reviewer Services</div>
      <hr>
      <ul>
        <li>  • IEEE Transactions on Knowledge and Data Engineering (TKDE).</li>
        <li>  • NeurIPS 2025.</li>
        <li>  • ACMMM 2025.</li>
        <li>  • ACL 2023、2024.</li>
        <li>  • EMNLP 2023、2024.</li>
        <li>  • CVPR 2025.</li>
        <li>  • Knowledge-Based Systems (KBS).</li>
        <li>  • Journal of Software (软件学报).</li>
      </ul>
    </div>
  </div>
</div>


<!-- ==========================================
             Academic Activities
=========================================== -->
<!--<div id="academicactivities">-->
<!--  <div class="row container">-->
<!--    <div class="row">-->
<!--      <div class="title">🛠 Academic Activities</div>      -->
<!--      <hr>-->
<!--      <h7>Conference Reviewers</h7>-->
<!--      <ul>-->
<!--        <li>  • IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023</li>-->
<!--        <li>  • IEEE/CVF International Conference on Computer Vision (ICCV), 2023</li>-->
<!--        <li>  • European Conference on Computer Vision (ECCV), 2022</li>-->
<!--      </ul>-->
<!--      <h7>Journal Reviewers</h7>-->
<!--      <ul>-->
<!--        <li>  • Pattern Recognition (PR)</li>-->
<!--        <li>  • ISPRS Journal</li>-->
<!--        <li>  • Information Sciences</li>-->
<!--        <li>  • ACM Transactions on Multimedia Computing Communications and Applications (ACM TOMM)</li>-->
<!--        <li>  • IEEE Transactions on Geoscience and Remote Sensing (IEEE TGRS) </li>-->
<!--        <li>  • IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (IEEE JSTARS) </li>-->
<!--      </ul>-->
<!--    </div>-->
<!--  </div>-->
<!--</div>-->

  
<!-- ==========================================
                   Awards
=========================================== -->
<div id="awards">
  <div class="row container">
    <div class="row">
      <div class="title">🎖 Fundings</div>      
      <hr>
      <ul>
        <li> • 2025: The 76th batch of China Postdoctoral Science Foundation general projects.  </li>
        <li> • 2025: Key research and development projects (重点研发计划), project backbone.  </li>
        <!-- <li>  • 2024: Shuimu Tsinghua Scholar for Postdoc Researcher (清华大学水木学者).</li>
        <li>  • 2024: CAS President Scholarship (中国科学院院长奖).</li>
        <li>  • 2020: Merit Student Award.</li>
        <li>  • 2018: National Scholarship (0.3%).</li>
        <li>  • 2018: American Mathematical Contest In Modeling (MCM) Honorable Mention Award.</li>
        <li>  • 2017: First Prize of Anhui Competition Area in Contemporary Undergraduate Mathematical Contest in Modeling (CUMCM).</li> -->

      </ul>
    </div>
  </div>
</div>


<center>
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=900&t=tt&d=uhOdw7jm_QVpMd4bbp2rp0d4UXNZ131O2FTe18POhdA&co=2d78ad&cmo=ff0000&cmn=ff9f00&ct=ffffff'></script>
</center>

<p></p>
<center>
    Copyright © 2022 &nbsp; Kaiwen Wei. All Rights Reserved.
</center>
    
</body></html>
  
