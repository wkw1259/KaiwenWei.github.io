<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="Kaiwen Wei">
  <title>Kaiwen Wei's Homepage</title>

  <!-- CSS  -->
  <link href="./materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./style.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link rel="shortcut icon" href="./cqu_short.png">
<script type="text/javascript" src="./jquery-1.12.4.min.js.ä¸‹è½½"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://kaiwenwei.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://kaiwenwei.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#publications">Publications</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#WorkExperience">Work Experience</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#education">Education</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://kaiwenwei.github.io/#awards">Awards</a></li>
        </ul>
        </ul>
      </div>
    </nav>
  </div>
  

<!--==========================================
                   Profile
===========================================-->

<div id="home" class="parallax-container scrollspy">


  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="./wkw.jpg" width="319">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name"><font color="#000000">Kaiwen Wei (é­æ¥·æ–‡)</h5>
        <hr>
        <h6 class="profile-link"><b>Assistant Researcher in Chongqing University</b></h6>
        <h6 class="profile-link"><b>Ph.D. at University of Chinese Academy of Sciences/Aerospace Information Research Institute, Chinese Academy of Sciences</b></h6>
        <h6 class="profile-link"><b>Email: weikaiwen@cqu.edu.cn</b></h6>
      
    </div>    
  
  </div>
  
<!--  <div class="parallax"><img src="./bg-yds3.jpg" alt="Unsplashed background img 1" style="display: block; transform: translate3d(-50%, 153px, 0px);"></div>-->

</div>
  
 

<!--==========================================
                   About
===========================================-->
<div id="biography">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title"> Biography [<a href="https://scholar.google.com/citations?hl=zh-CN&user=WfAS1yMAAAAJ"><b>Google Scholar</b></a>] </a>
</div>
    <hr>
    </div>
    
    <div class="row">
      <p>
        Kaiwen Wei is currently an Assistant Researcher at the College of Computer Science, Chongqing University (since September 2024). He obtained his Ph.D. (direct-track) from the National Key Laboratory of Target Cognition and Application Technology, Aerospace Information Research Institute (AIR), Chinese Academy of Sciences (September 2019-July 2024), under the supervision of Researcher Zhi Guo and Researcher Xian Sun. He completed his undergraduate studies at Chongqing University (September 2015-June 2019). During his doctoral studies, he interned at leading technology companies including Meituan, Alibaba DAMO Academy, and Kuaishou, accumulating rich industry experience and building strong industry-academia collaboration networks. 
        <!-- I am an Assistant Researcher at Chongqing Universityâ€™s College of Computer Science (IEEE/CCF Member), leading a China Postdoctoral Science Foundation project and participating in a National Key R&D Program. Holding a Ph.D. from the Chinese Academy of Sciencesâ€™ Key Lab of Target Cognition (2019â€“2024) and a B.Eng. from Chongqing University (2015â€“2019), I interned at Meituan, Alibaba DAMO, and Kuaishou. My research focuses on NLP and Multimodal Learning, with 24 publications (14 first/corresponding-author in TPAMI, ACL, AAAI, etc.).
         Dongshuo Yin is currently a postdoc researcher in <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, working with <a href="https://www.tsinghua.edu.cn/info/1167/108283.htm">Prof. Shimin Hu</a> at <a href="https://www.cs.tsinghua.edu.cn/">the Department of Computer Science and Technology</a>. Before that, Dongshuo Yin received the PhD degree from <a href="https://eece.ucas.ac.cn/">School of Electronic, Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a> & <a href="http://www.aircas.ac.cn/">Institute of Electronics (Aerospace Information Research Institute), Chinese Academy of Sciences</a>, advised by <a href="http://people.ucas.ac.cn/~sunxian">Prof. Xian Sun</a>.         Dongshuo Yin's research interests include deep learning and computer vision, with a focus on remote sensing, parameter-efficient fine tuning, 3D weakly supervised object detection. -->
</a>
      </p>

      <p>
        His research focuses on cutting-edge AI technologies, particularly in <b>natural language processing</b> (NLP), <b>multimodal learning</b> (MM), <b>large language models</b> (LLMs), and <b>AI-driven medical applications</b> (AI+Medical), with a strong commitment to advancing intelligent systems for real-world healthcare solutions.
        <!-- I am an Assistant Researcher at Chongqing Universityâ€™s College of Computer Science (IEEE/CCF Member), leading a China Postdoctoral Science Foundation project and participating in a National Key R&D Program. Holding a Ph.D. from the Chinese Academy of Sciencesâ€™ Key Lab of Target Cognition (2019â€“2024) and a B.Eng. from Chongqing University (2015â€“2019), I interned at Meituan, Alibaba DAMO, and Kuaishou. My research focuses on NLP and Multimodal Learning, with 24 publications (14 first/corresponding-author in TPAMI, ACL, AAAI, etc.).
         Dongshuo Yin is currently a postdoc researcher in <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, working with <a href="https://www.tsinghua.edu.cn/info/1167/108283.htm">Prof. Shimin Hu</a> at <a href="https://www.cs.tsinghua.edu.cn/">the Department of Computer Science and Technology</a>. Before that, Dongshuo Yin received the PhD degree from <a href="https://eece.ucas.ac.cn/">School of Electronic, Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a> & <a href="http://www.aircas.ac.cn/">Institute of Electronics (Aerospace Information Research Institute), Chinese Academy of Sciences</a>, advised by <a href="http://people.ucas.ac.cn/~sunxian">Prof. Xian Sun</a>.         Dongshuo Yin's research interests include deep learning and computer vision, with a focus on remote sensing, parameter-efficient fine tuning, 3D weakly supervised object detection. -->
</a>
      </p>

<!--      <p>-->
<!--        Dongshuo Yin received the B. E. degree from XXXXX, China, in 2019.-->
<!--      </p>-->
      <p>
        é­æ¥·æ–‡ï¼Œç°ä¸ºé‡åº†å¤§å­¦è®¡ç®—æœºå­¦é™¢åŠ©ç†ç ”ç©¶å‘˜ï¼ˆ2024å¹´9æœˆè‡³ä»Šï¼‰ï¼Œæ­¤å‰åœ¨ä¸­å›½ç§‘å­¦é™¢ç©ºå¤©ä¿¡æ¯åˆ›æ–°ç ”ç©¶é™¢ç›®æ ‡è®¤çŸ¥ä¸åº”ç”¨æŠ€æœ¯å›½å®¶çº§é‡ç‚¹å®éªŒå®¤è·å¾—ç›´åšå­¦ä½ï¼ˆ2019å¹´9æœˆ-2024å¹´7æœˆï¼‰ï¼Œå¸ˆä»éƒ­æ™ºç ”ç©¶å‘˜å’Œå­™æ˜¾ç ”ç©¶å‘˜ï¼ˆå›½å®¶æ°é’ï¼‰ã€‚æœ¬ç§‘é˜¶æ®µå°±è¯»äºé‡åº†å¤§å­¦ï¼ˆ2015å¹´9æœˆ-2019å¹´6æœˆï¼‰ã€‚åšå£«æœŸé—´æ›¾å…ˆååœ¨ç¾å›¢ã€é˜¿é‡Œå·´å·´è¾¾æ‘©é™¢å’Œå¿«æ‰‹ç­‰å¤´éƒ¨ä¼ä¸šå®ä¹ ï¼Œç§¯ç´¯äº†ä¸°å¯Œçš„å·¥ä¸šç•Œç»éªŒå¹¶å»ºç«‹äº†è‰¯å¥½çš„äº§å­¦ç ”åˆä½œç½‘ç»œã€‚
      </p>
      <p> 
        æˆ‘çš„ç ”ç©¶èšç„¦äººå·¥æ™ºèƒ½å‰æ²¿é¢†åŸŸï¼Œä¸»è¦åŒ…æ‹¬ï¼š<b>è‡ªç„¶è¯­è¨€å¤„ç†</b>ï¼ˆNLPï¼‰çš„åŸºç¡€ç†è®ºä¸åº”ç”¨åˆ›æ–°ã€<b>å¤šæ¨¡æ€å­¦ä¹ </b>ï¼ˆMMï¼‰çš„è·¨åŸŸèåˆæ–¹æ³•ã€<b>å¤§è¯­è¨€æ¨¡å‹</b>ï¼ˆLLMsï¼‰çš„ä¼˜åŒ–ä¸éƒ¨ç½²ï¼Œä»¥åŠ<b>äººå·¥æ™ºèƒ½ä¸åŒ»å­¦çš„äº¤å‰ç ”ç©¶</b>ï¼ˆAI+Medicalï¼‰ï¼Œè‡´åŠ›äºæ¨åŠ¨æ™ºèƒ½æŠ€æœ¯åœ¨åŒ»ç–—å¥åº·ç­‰å…³é”®é¢†åŸŸçš„è½åœ°åº”ç”¨ã€‚

      </p>
    
      <p>
      å¦‚æœå¯¹ç›¸å…³å·¥ä½œæ„Ÿå…´è¶£ï¼Œæ¬¢è¿é‚®ä»¶è”ç³»æˆ‘ã€‚åŒæ—¶ï¼Œéå¸¸æ¬¢è¿å¯¹ç§‘å­¦ç ”ç©¶æ„Ÿå…´è¶£çš„æœ¬ç§‘ç”Ÿæˆ–ç ”ç©¶ç”Ÿè”ç³»æˆ‘è¿›è¡Œçº¿ä¸‹ï¼ˆé‡åº†å¤§å­¦è™æºªæ ¡åŒºï¼‰æˆ–çº¿ä¸Šçš„åˆä½œäº¤æµã€‚
      </p>

  </div>
</div>



<!--==========================================
                   News
===========================================-->
<div id="news">

  <div class="row container">
    <div class="row">
      <div class="title">ğŸ”¥ News</div>
      <hr>
    </div>
    <div class="row">
      <ul>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2025 May: &nbsp; 4 papers (1 main track and 3 findings) is accepted by ACL 2025.
          <!-- â€¢ 2025: &nbsp; Mona (CVPR 2025) has been reported by <a href="https://mp.weixin.qq.com/s/qL8IzpaFUWKBxUsodshH0w"><b>Extreme Mart</b></a>, <a href="https://mp.weixin.qq.com/s/OM0hZMX_KcEXvt0DorPhOw"><b>PaperWeekly</b></a>, <a href="https://mp.weixin.qq.com/s/NsNRmzn_haq_ly63W0WjAQ"><b>QbitAI (é‡å­ä½)</b></a>, and <a href="https://mp.weixin.qq.com/s/15bO4RD8Iu0TcEfvHGYF0A"><b>Synces (æœºå™¨ä¹‹å¿ƒ)</b></a> ! -->
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2024 Nov: &nbsp; One paper was accepted at ICASSP 2025.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2024 Oct: &nbsp; One paper was accepted at COLING 2025.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2024 Aug: &nbsp; One paper was accepted at TPAMI.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2024 Aug: &nbsp; One paper was accepted at NLPCC 2024.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2024 Jul: &nbsp; One paper was accepted at ECAI 2024.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2024 May: &nbsp; One paper was accepted at COLING 2024.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2024 Feb: &nbsp; Two papers were accepted at AAAI 2024.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2023 Dec: &nbsp; Two papers were accepted at EMNLP 2023.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2023 Oct: &nbsp; One paper was accepted at Electronics.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2023 Jul: &nbsp; Two papers were accepted at ACL 2023.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2022 Jun: &nbsp; One paper was accepted at CVPR 2023.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2023 Jan: &nbsp; One paper was accepted at KBS.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2022 Dec: &nbsp; One paper was accepted at TALLIP.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2022 Nov: &nbsp; One paper was accepted at TKDE.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2022 Oct: &nbsp; One paper was accepted at EMNLP 2022.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2022 Oct: &nbsp; One paper was accepted at KBS 2022.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          â€¢ 2021 Aug: &nbsp; One paper was accepted at ACL 2021.
        </li>

      <!-- <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2024: &nbsp; Awarded with <font color="#0000dd"><b>CAS President Scholarship! (ä¸­å›½ç§‘å­¦é™¢é™¢é•¿å¥–ï¼Œ<1%)</b></font> 
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2024: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/document/10385180"><b>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</b></a>.
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2023: &nbsp; Our paper on Nature Communications has been read <a href="https://www.nature.com/articles/s41467-023-37136-1"><b>10,000+</b></a> times and has been reported by <a href="https://new.qq.com/rain/a/20230617A0131300.html"><b>Tencent News</b></a>, <a href="https://www.163.com/dy/article/I0F7AM0M0511D05M.html"><b>Netease News</b></a> and <a href="https://www.sohu.com/a/657874198_121123740"><b>Sohu News</b></a> !
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2023: &nbsp; One paper is accepted by <a href="https://www.nature.com/articles/s41467-023-37136-1"><b>Nature Communications</b></a> !
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2023: &nbsp; One paper is accepted by <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Yin_1_VS_100_Parameter-Efficient_Low_Rank_Adapter_for_Dense_Predictions_CVPR_2023_paper.html"><b>CVPR 2023 Main Track</b></a> !
      </li>
      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2023: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/10102360/"><b>IEEE Transactions on Intelligent Transportation Systems (TITS)</b></a>.
      </li>

      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2023: &nbsp; One paper is accepted by <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.html"><b>ICCV 2023 Main Track</b></a> !
      </li>

      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2022: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/9956875"><b>IEEE Transactions on Transactions on Multimedia (TMM)</b></a>.
      </li>

      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2022: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/9832637"><b>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</b></a>.
      </li>

      <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
        â€¢ 2022: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/9884328"><b>IEEE IGARSS 2022</b></a>.
      </li> -->

      </ul>
    </div>
  </div>
</div>



<!--==========================================
                   Publications
===========================================-->
<div class="section publications-section scrollspy" id="publications">

  <div class="row container">
    <div class="row">
      <div class="title">ğŸ“ Publications</div>
      <hr>
    </div>

        <!-- Publication 1 -->
        <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/1.pic.jpg" alt="Implicit Event Argument Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Implicit Event Argument Extraction With Argument-Argument Relational Knowledge</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Sun Xian, Zequn Zhang, Li Jin, Jingyuan Zhang, Jianwei Lv, and Zhi Guo</div>  
              <div class="paper-conf"><em><font color="#ff0000"><b>IEEE Transactions on Knowledge and Data Engineering</b></font> <b>(TKDE, SCI, CCF-A)</b></em></div>
              <div>
                  [<a href="https://ieeexplore.ieee.org/document/9963576">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning, </span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 2 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/2.pic.jpg" alt="Multimodal Cross-lingual Summarization">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Multimodal Cross-lingual Summarization for Videos: A Revisit in Knowledge Distillation Induced Triple-stage Training Method</div>
              <div class="paper-author">Nayu Liu<sup>*</sup>, <b>Kaiwen Wei<sup>*</sup></b>, Yong Yang, Jianhua Tao, Xian Sun, Fanglong Yao, Hongfeng Yu, Li Jin , Zhao Lv, and Cunhang Fan</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>IEEE Transactions on Pattern Analysis and Machine Intelligence</b></font> <b>(TPAMI, SCI, CCF-A, co-first author)</b></em></div>
              <div>
                  [<a href="https://ieeexplore.ieee.org/document/10643687">Paper</a>] [<a href="https://github.com/fchest/DKDSSD">Code</a>]
                  <div class="keywords">
                      <span class="keyword">Multi-modal Summary Generation, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 3 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/3.pic.jpg" alt="Open Information Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Guide the Many-to-One Assignment: Open Information Extraction via IoU-aware Optimal Transport</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Yang Yiran, Li Jin, Xian Sun, Zequn Zhang, Jingyuan Zhang, Xiaoyu Li, Linhao Zhang, Jintao Liu, and Zhi Guo.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>ACL 2023</b></font> <b>(ACL, Long paper, CCF-A)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2023.acl-long.272/">Paper</a>] 
                  <div class="keywords">
                      <span class="keyword">Information Extraction, </span>
                      <span class="keyword">Open-domain, </span>
                      <span class="keyword">Optimal Transport, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 4 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/4.pic.jpg" alt="Implicit Event Argument Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Trigger is Not Sufficient: Exploiting Frame-aware Knowledge for Implicit Event Argument Extraction</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Sun Xian, Zequn Zhang, Jingyuan Zhang, Zhi Guo, and Li Jin.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>ACL 2021</b></font> <b>(ACL, Long paper, CCF-A)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2021.acl-long.360/">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 5 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/5.pic.jpg" alt="Video Event Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Multi-View Interactions with Knowledge Distillation for Video Event Extraction</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Du Runyan, Li Jin, Jian Liu, Jianhua Yin, Linhao Zhang, Jintao Liu, Nayu Liu, Jingyuan Zhang, and Zhi Guo.</div>  
              <div class="paper-conf"><em><font color="#ff0000"><b>AAAI 2024</b></font> <b>(AAAI, CCF-A)</b></em></div>
              <div>
                  [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/29891">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Multi-modal, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 6 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/6.pic.jpg" alt="Event Causality Reasoning">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Multimodal Event Causality Reasoning with Scene Graph Enhanced Interaction Network</div>
              <div class="paper-author">Jintao Liu, <b>Kaiwen Wei<sup>â€ </sup></b>, and Chenglong Liu.</div>
              <div class="paper-conf"><em><font color="#ff0000"><b>AAAI 2024</b></font> <b>(AAAI, CCF-A, Corresponding author)</b></em></div>
              <div>
                  [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28724">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Causality Reasoning, </span>
                      <span class="keyword">Scene Graph, </span>
                      <span class="keyword">Multi-modal, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 7 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/7.pic.jpg" alt="Chain-of-Specificity">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Chain-of-Specificity: Enhancing Task-Specific Constraint Adherence in Large Language Models</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Jiang Zhong, Jingyuan Zhang, Hongzhi Zhang, Fuzheng Zhang, Di Zhang, Li Jin, and Yue Yu.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>COLING 2024</b></font> <b>(COLING, CCF-B)</b></em></div>
              <div>
                  [<a href="https://arxiv.org/abs/2402.15526">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Chain-of-Thought, </span>
                      <span class="keyword">Prompt Learning, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Large Language Model</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 8 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/8.pic.jpg" alt="Multimodal Cross-Lingual Summarization">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Assist Non-native Viewers: Multimodal Cross-Lingual Summarization for How2 Videos</div> 
              <div class="paper-author">Liu Nayu*, <b>Kaiwen Wei</b>*, Sun Xian, Hongfeng Yu, Fanglong Yao, Li Jin, Zhi Guo, and Guangluan Xu.</div>
              <div class="paper-conf"><em><font color="#ff0000"><b>EMNLP 2022</b></font> <b>(EMNLP, Long paper, CCF-B, Co-first author)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2022.emnlp-main.468/">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Summarization, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Multi-modal, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 9 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/9.pic.jpg" alt="Demonstration Learning">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">Let Me Check the Examples: Enhancing Demonstration Learning via Explicit Imitation</div>
              <div class="paper-author">Sirui Wang, <b>Kaiwen Wei<sup>â€ </sup></b>, Hongzhi Zhang, Yuntao Li, and Wei Wu.</div>
              <div class="paper-conf"><em><font color="#ff0000"><b>ACL 2023</b></font> <b>(ACL, Short paper, CCF-A, Corresponding author)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2023.acl-short.93/">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Prompt-tuning, </span>
                      <span class="keyword">In-context Learning, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 10 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/10.pic.jpg" alt="HEFT Framework">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">HEFT: A History-Enhanced Feature Transfer framework for incremental event detection</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Zhang Zequn, Li Jin, Zhi Guo, Shuchao Li, Weihong Wang, and Jianwei Lv.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>Knowledge-Based Systems</b></font> <b>(KBS, SCI)</b></em></div>
              <div>
                  [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0950705122008061">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Continual Learning, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 11 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/11.pic.jpg" alt="Cross-lingual Relation Extraction">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">More than Syntaxes: Investigating Semantics to Zero-shot Cross-lingual Relation Extraction and Event Argument Role Labelling</div>
              <div class="paper-author"><b>Kaiwen Wei</b>, Jin Li, Zequn Zhang, Zhi Guo, Xiaoyu Li, and Qing Liu.</div>
              <div class="paper-conf"><em><font color="#ff0000"><b>ACM Transactions on Asian and Low-Resource Language Information Processing</b></font> <b>(TALLIP, SCI)</b></em></div>
              <div>
                  [<a href="https://dl.acm.org/doi/10.1145/3582261">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Event Extraction, </span>
                      <span class="keyword">Multi-lingual, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

      <hr class="publication-hr">

      <!-- Publication 12 -->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./publications/short_cuts/12.pic.jpg" alt="TAeKD Framework">
          </div>
          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <div class="paper-title">TAeKD: Teacher Assistant Enhanced Knowledge Distillation for Closed-Source Multilingual Neural Machine Translation</div>
              <div class="paper-author">Bo Lv, Xin Liu, <b>Kaiwen Wei</b>, Ping Luo, and Yue Yu.</div> 
              <div class="paper-conf"><em><font color="#ff0000"><b>COLING 2024</b></font> <b>(COLING, CCF-B)</b></em></div>
              <div>
                  [<a href="https://aclanthology.org/2024.lrec-main.1350/">Paper</a>]
                  <div class="keywords">
                      <span class="keyword">Neural Machine Translation, </span>
                      <span class="keyword">Knowledge Distillation, </span>
                      <span class="keyword">Large Language Model, </span>
                      <span class="keyword">Natural Language Processing, </span>
                      <span class="keyword">Deep Learning</span>
                  </div>
              </div>
          </div>
      </div>

<hr class="publication-hr">


</div>





<!-- ==========================================
                   Work experience
=========================================== -->
<div id="WorkExperience">

  <div class="row container">
    <div class="row">
      <div class="title">ğŸ’¼ Work Experience</div>
      <hr>
    </div>

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <!-- <a href="https://www.tsinghua.edu.cn/" target="_blank"> -->
          <img src="./cqu_long.png" width="260" align="center" class="img-responsive edu-img">
        </a>
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <p></p>
        <p></p>
        <p></p>
        <div class="degree"></div>
        <div class="degree"><b>Assistant Researcher</b> in <a href="https://cs.cqu.edu.cn/index.htm">College of Computer Science, Chongqing University</a>, Chongiqng, China</div>
        <div class="date">Sep. 2024 - June. 2026</div>
      </div>
  </div>
  <hr class="publication-hr">
    <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./kuaishou.jpg" width="366">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Kuaishou Inc.</div>
            <div class="paper-author">LLM Group</div>
            <div class="paper-conf"><em><b>Internship</b>: 2024.2-2024.06</em></div>
<!--            <div>-->
<!--                [<a href="https://www.grss-ieee.org/technical-committees/image-analysis-and-data-fusion/?tab=data-fusion-contest">Website</a>]-->
<!--                [<a href="https://github.com/AICyberTeam/DFC2023-baseline">Baseline</a>]-->
<!--            </div>-->
          </div>
      </div>
      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./DAMO.png" width="366">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Alibaba Group</div>
            <div class="paper-author">DAMO Academy</div>
            <div class="paper-conf"><em><b>Internship</b>: 2023.7-2024.1</em></div>
          </div>
      </div>
      <hr class="publication-hr">
      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./meituan.jpg" width="366">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Meituan Inc.</div>
          <div class="paper-author">Knowlege Graph Group</div>
          <div class="paper-conf"><em><b>Internship</b>: 2022.11-2023.6</em></div>
        </div>
    </div>
<!--      <hr class="publication-hr">-->
</div>

<!--==========================================
                   Education
===========================================-->
<div id="education">
  <div class="row container">
    <div class="row">
      <div class="title">ğŸ“ Education</div>
      <hr>
    </div>
    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <!-- <a href="https://www.tsinghua.edu.cn/" target="_blank"> -->
          <img src="./cqu_long.png" width="260" align="center" class="img-responsive edu-img">
        </a>
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <p></p>
        <p></p>
        <p></p>
        <div class="degree"></div>
        <div class="degree"><b>Undergraduate</b> in <a href="https://cs.cqu.edu.cn/index.htm">School of Microelectronics and Communication Engineering, Chongqing University</a>, Chongiqng, China</div>
        <div class="date">Sep. 2015 - June. 2019</div>
      </div>
  </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <!-- <a href="https://www.ucas.ac.cn/" target="_blank"> -->
            <img src="./University_of_Chinese_Academy_of_Sciences-Logo.png" width="380" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>Ph.D.</b> in <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a>, Beijing, China</div>
          <div class="date">Sep. 2019 - June. 2024</div>
        </div>
    </div>

<!--    <div class="row">-->
<!--        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">-->
<!--          <a href="https://www.whu.edu.cn/" target="_blank">-->
<!--            <img src="./whu.jpeg" style="width:110px;height:100px;" align="center" class="img-responsive edu-img">-->
<!--          </a>-->
<!--        </div>-->

<!--        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">-->
<!--          <p></p>-->
<!--          <p></p>-->
<!--          <p></p>-->
<!--          <div class="degree"><b>B.E.</b> degree from <a href="https://www.whu.edu.cn/">Wuhan University</a>, Wuhan, China</div>-->
<!--          <div class="date">Sep. 2015 - Jun.2019</div>-->
<!--        </div>-->
<!--    </div>-->
  </div>
</div>
      
<!--==========================================
              Reviewer Services
===========================================-->

<div id="reviewerServices">
  <div class="row container">
    <div class="row">
      <div class="title">ğŸ‘“ Reviewer Services</div>
      <hr>
      <ul>
        <li>â€ƒ â€¢ IEEE Transactions on Knowledge and Data Engineering (TKDE).</li>
        <li>â€ƒ â€¢ NeurIPS 2025.</li>
        <li>â€ƒ â€¢ ACMMM 2025.</li>
        <li>â€ƒ â€¢ ACL 2023ã€2024.</li>
        <li>â€ƒ â€¢ EMNLP 2023ã€2024.</li>
        <li>â€ƒ â€¢ CVPR 2025.</li>
        <li>â€ƒ â€¢ Knowledge-Based Systems (KBS).</li>
        <li>â€ƒ â€¢ Journal of Software (è½¯ä»¶å­¦æŠ¥).</li>
      </ul>
    </div>
  </div>
</div>


<!-- ==========================================
             Academic Activities
=========================================== -->
<!--<div id="academicactivities">-->
<!--  <div class="row container">-->
<!--    <div class="row">-->
<!--      <div class="title">ğŸ›  Academic Activities</div>      -->
<!--      <hr>-->
<!--      <h7>Conference Reviewers</h7>-->
<!--      <ul>-->
<!--        <li>â€ƒ â€¢ IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023</li>-->
<!--        <li>â€ƒ â€¢ IEEE/CVF International Conference on Computer Vision (ICCV), 2023</li>-->
<!--        <li>â€ƒ â€¢ European Conference on Computer Vision (ECCV), 2022</li>-->
<!--      </ul>-->
<!--      <h7>Journal Reviewers</h7>-->
<!--      <ul>-->
<!--        <li>â€ƒ â€¢ Pattern Recognition (PR)</li>-->
<!--        <li>â€ƒ â€¢ ISPRS Journal</li>-->
<!--        <li>â€ƒ â€¢ Information Sciences</li>-->
<!--        <li>â€ƒ â€¢ ACM Transactions on Multimedia Computing Communications and Applications (ACM TOMM)</li>-->
<!--        <li>â€ƒ â€¢ IEEE Transactions on Geoscience and Remote Sensing (IEEE TGRS) </li>-->
<!--        <li>â€ƒ â€¢ IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (IEEE JSTARS) </li>-->
<!--      </ul>-->
<!--    </div>-->
<!--  </div>-->
<!--</div>-->

  
<!-- ==========================================
                   Awards
=========================================== -->
<div id="awards">
  <div class="row container">
    <div class="row">
      <div class="title">ğŸ– Fundings</div>      
      <hr>
      <ul>
        <li> â€¢ 2025: The 76th batch of China Postdoctoral Science Foundation general projects.  </li>
        <li> â€¢ 2025: Key research and development projects (é‡ç‚¹ç ”å‘è®¡åˆ’), project backbone.  </li>
        <!-- <li>â€ƒ â€¢ 2024: Shuimu Tsinghua Scholar for Postdoc Researcher (æ¸…åå¤§å­¦æ°´æœ¨å­¦è€…).</li>
        <li>â€ƒ â€¢ 2024: CAS President Scholarship (ä¸­å›½ç§‘å­¦é™¢é™¢é•¿å¥–).</li>
        <li>â€ƒ â€¢ 2020: Merit Student Award.</li>
        <li>â€ƒ â€¢ 2018: National Scholarship (0.3%).</li>
        <li>â€ƒ â€¢ 2018: American Mathematical Contest In Modeling (MCM) Honorable Mention Award.</li>
        <li>â€ƒ â€¢ 2017: First Prize of Anhui Competition Area in Contemporary Undergraduate Mathematical Contest in Modeling (CUMCM).</li> -->

      </ul>
    </div>
  </div>
</div>


<center>
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=900&t=tt&d=uhOdw7jm_QVpMd4bbp2rp0d4UXNZ131O2FTe18POhdA&co=2d78ad&cmo=ff0000&cmn=ff9f00&ct=ffffff'></script>
</center>

<p></p>
<center>
    Copyright Â© 2022 &nbsp; Kaiwen Wei. All Rights Reserved.
</center>
    
</body></html>
  
